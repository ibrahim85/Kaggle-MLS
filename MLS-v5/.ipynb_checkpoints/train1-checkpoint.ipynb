{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RND = 123\n",
    "np.random.seed(RND)\n",
    "import random\n",
    "random.seed(RND)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "RUN = 'C'\n",
    "MODELS_DIR = '/d3/caches/kaggle-mls-v5/models/' + RUN\n",
    "TFB_DIR = '/tmp-persistent/mls5/' + RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOP_LEN 942\n"
     ]
    }
   ],
   "source": [
    "VAL_SIZE = 0.1\n",
    "\n",
    "MSGS_CACHE_DIR = 'out/msgs-256'\n",
    "\n",
    "SAMPLING_RATE = 400\n",
    "N_SAMPLES = 240000\n",
    "N_CHANNELS = 16\n",
    "\n",
    "N_FFT=512\n",
    "N_MELS=256\n",
    "DESIRED_MSG_W = 256\n",
    "HOP_LEN = 1 + int(N_SAMPLES / (DESIRED_MSG_W - 1))\n",
    "\n",
    "WARM_CACHE = True\n",
    "\n",
    "print 'HOP_LEN', HOP_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make sure output dirs exist\n",
    "for v in [MSGS_CACHE_DIR, MODELS_DIR, TFB_DIR]: \n",
    "    if not os.path.isdir(v): \n",
    "        os.makedirs(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load inout files list\n",
    "input_df = pd.read_csv('out/input_files.csv', index_col='file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split inout files into train/test sets\n",
    "train_df = input_df[input_df['class'] != -1]\n",
    "test_df = input_df[input_df['class'] == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_trainval_files = train_df.index.tolist()\n",
    "X_trainval_patients = np.vstack((train_df['patient_1'], train_df['patient_2'], train_df['patient_3']))\\\n",
    "    .T.astype(np.float32)\n",
    "y_trainval = np.array(train_df['class'], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_batch(X_files=None, X_patients=None, y=None, start_ix=0, n_samples=1, silent=True):\n",
    "    \n",
    "    X_msgs_batch = np.zeros((n_samples, N_MELS, DESIRED_MSG_W, N_CHANNELS), dtype=np.float32)\n",
    "    X_patients_batch = np.zeros((n_samples, X_patients.shape[1]), dtype=np.float32)        \n",
    "    y_batch = np.zeros([n_samples, 2], dtype=np.float32)\n",
    "    means = np.zeros([n_samples, N_CHANNELS], dtype=np.float32)\n",
    "        \n",
    "    r = range(n_samples) if silent else tqdm(range(n_samples))\n",
    "\n",
    "    for i in r:\n",
    "        ii  = (i + start_ix) % len(X_files)\n",
    "        \n",
    "        mat_f = X_files[ii]\n",
    "        mat_cache_fp = MSGS_CACHE_DIR + '/' + mat_f + '.msgs.mem'\n",
    "        \n",
    "        # check if msgs are chached\n",
    "        if not os.path.isfile(mat_cache_fp):\n",
    "\n",
    "            mat_fp = input_df.ix[mat_f]['path']\n",
    "            waves = lib.read_mat(mat_fp)\n",
    "            \n",
    "            msgs = np.zeros((N_CHANNELS, N_MELS, DESIRED_MSG_W), dtype=np.float32)\n",
    "\n",
    "            for ch in range(16):\n",
    "                msgs[ch] = lib.compute_msg(waves[ch], \\\n",
    "                      desired_msg_w=DESIRED_MSG_W, hop_length=HOP_LEN, \\\n",
    "                      n_fft=N_FFT, n_mels=N_MELS, sr=SAMPLING_RATE)\n",
    "                            \n",
    "            # move channel axis, shape is now: (ix, h, w, ch)\n",
    "            msgs_t = np.swapaxes(msgs, 0, 1)\n",
    "            msgs_t = np.swapaxes(msgs_t, 1, 2)\n",
    "\n",
    "            X_msgs_batch[i] = msgs_t\n",
    "                \n",
    "            # save to cache\n",
    "            X_msgs_batch[i].tofile(mat_cache_fp)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            X_msgs_batch[i] = np.fromfile(mat_cache_fp, dtype=np.float32).\\\n",
    "                reshape((N_MELS, DESIRED_MSG_W, N_CHANNELS))\n",
    "                \n",
    "            # compute means\n",
    "            means[i] = np.mean(X_msgs_batch.T.reshape(N_CHANNELS, -1), axis=1)\n",
    "\n",
    "        X_patients_batch[i] = X_patients[ii]\n",
    "        y_batch[i] = [1., 0.] if y[ii] else [0., 1.]\n",
    "    \n",
    "    return X_msgs_batch, X_patients_batch, y_batch, means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 1038/6672 [02:43<23:41,  3.96it/s]"
     ]
    }
   ],
   "source": [
    "# warm cache\n",
    "if WARM_CACHE:\n",
    "    \n",
    "    means = []\n",
    "\n",
    "    X_files = input_df.index.tolist()\n",
    "    X_patients = np.vstack((input_df['patient_1'], input_df['patient_2'], input_df['patient_3']))\\\n",
    "        .T.astype(np.float32)\n",
    "    y = np.zeros((len(X_files), 1), dtype=np.float32)\n",
    "    \n",
    "    start = 0\n",
    "    stop = len(X_files)\n",
    "\n",
    "    for i in tqdm(xrange(start, stop)):\n",
    "        _msgs, _patients, _ys, _means = \\\n",
    "            gen_batch(X_files, X_patients, y, start_ix=i, n_samples=1, silent=True)\n",
    "        means.append(_means[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 85.0632782 ,  86.75190735,  81.09435272,  82.0920639 ,\n",
       "        83.20228577,  85.52071381,  83.13315582,  81.75543213,\n",
       "        82.01451874,  75.06038666,  79.26768494,  78.29553223,\n",
       "        81.36355591,  81.65673065,  79.51850128,  77.41757202], dtype=float32)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(means, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = gen_batch(X_files, X_patients, y, start_ix=i, n_samples=1, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mm = b[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  93.77540588,   94.47314453,   95.14610291,   96.586586  ,\n",
       "         99.23521423,   97.10848999,   93.72658539,   98.5067215 ,\n",
       "         83.79309845,  126.31234741,   86.83683777,   84.59996796,\n",
       "         90.30253601,   93.17021942,   86.09326935,   86.47769165], dtype=float32)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(mm.T.reshape(mm.T.shape[0], -1), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 256, 256)\n",
      "[ 99.34836578  95.00201416  93.32743835  88.01261902  91.46595001\n",
      "  97.46484375  95.62434387  97.9276886   95.93054199  36.29848862\n",
      "  88.26551056  84.56757355  86.61559296  90.9962616   85.22241974\n",
      "  82.38331604]\n"
     ]
    }
   ],
   "source": [
    "a = np.swapaxes(b[0][0], 2, 1)\n",
    "a =  np.swapaxes(a, 1, 0)\n",
    "print a.shape\n",
    "print np.mean(a.reshape(a.shape[0], -1), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# split into train/test sets\n",
    "X_train_files, X_val_files, X_train_patients, X_val_patients, y_train, y_val = \\\n",
    "    train_test_split(X_trainval_files, X_trainval_patients, y_trainval, \\\n",
    "                     test_size=VAL_SIZE, random_state=RND)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_N_SAMPLES_PER_EPOCH 4272 of 4287\n"
     ]
    }
   ],
   "source": [
    "TRAIN_N_PER_BATCH = 16\n",
    "TRAIN_N_SAMPLES_PER_EPOCH = len(X_train_files)\n",
    "TRAIN_N_SAMPLES_PER_EPOCH -= TRAIN_N_SAMPLES_PER_EPOCH % TRAIN_N_PER_BATCH\n",
    "\n",
    "TRAIN_N_EPOCHS = 111\n",
    "\n",
    "print 'TRAIN_N_SAMPLES_PER_EPOCH', TRAIN_N_SAMPLES_PER_EPOCH, 'of', len(X_train_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 477/477 [00:16<00:00, 28.29it/s]\n"
     ]
    }
   ],
   "source": [
    "# generate validation set\n",
    "X_val_msgs, X_val_patients, y_val = \\\n",
    "    gen_batch(X_val_files, X_val_patients, y_val, n_samples=len(X_val_files), silent=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory for val set: 7.45G\n"
     ]
    }
   ],
   "source": [
    "print 'Memory for val set: %.2fG' % (X_val_msgs.size * 4. / pow(2, 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_ix = 0\n",
    "    \n",
    "# training data generator\n",
    "def train_generator():\n",
    "\n",
    "    global start_ix\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        b = gen_batch(\n",
    "            X_train_files, X_train_patients, y_train, \n",
    "            start_ix=start_ix, n_samples=TRAIN_N_PER_BATCH\n",
    "        )\n",
    "                \n",
    "        start_ix += TRAIN_N_SAMPLES_PER_EPOCH\n",
    "        \n",
    "        yield [b[0], b[1]], b[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import *\n",
    "from keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_msg = Input(shape=(N_MELS, DESIRED_MSG_W, N_CHANNELS), name='input_msg')\n",
    "\n",
    "x = Convolution2D(96, 3, 3, border_mode='same', activation='relu')(input_msg)\n",
    "# x = Convolution2D(128, 3, 3, border_mode='same', activation='relu')(x)\n",
    "x = MaxPooling2D((2, 4), strides=(2, 4))(x)\n",
    "\n",
    "x = Convolution2D(256, 3, 3, border_mode='same', activation='relu')(x)\n",
    "# x = Convolution2D(128, 3, 3, border_mode='same', activation='relu')(x)\n",
    "x = MaxPooling2D((2, 4), strides=(2, 4))(x)\n",
    "\n",
    "x = Convolution2D(512, 3, 3, border_mode='same', activation='relu')(x)\n",
    "# x = Convolution2D(256, 3, 3, border_mode='same', activation='relu')(x)\n",
    "# x = Convolution2D(256, 3, 3, border_mode='same', activation='relu')(x)\n",
    "x = MaxPooling2D((2, 2), strides=(2, 2))(x)\n",
    "\n",
    "# x = Convolution2D(512, 3, 3, border_mode='same', activation='relu')(x)\n",
    "# x = Convolution2D(512, 3, 3, border_mode='same', activation='relu')(x)\n",
    "x = Convolution2D(512, 3, 3, border_mode='same', activation='relu')(x)\n",
    "x = MaxPooling2D((2, 2), strides=(2, 2))(x)\n",
    "\n",
    "# x = Convolution2D(512, 3, 3, border_mode='same', activation='relu')(x)\n",
    "# x = Convolution2D(512, 3, 3, border_mode='same', activation='relu')(x)\n",
    "x = Convolution2D(512, 3, 3, border_mode='same', activation='relu')(x)\n",
    "x = MaxPooling2D((2, 2), strides=(2, 2))(x)\n",
    "\n",
    "conv_out = Flatten()(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_patient = Input(shape=(3,), name='input_patient')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = merge([conv_out, input_patient], mode='concat')\n",
    "x = Dense(2, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model(input=[input_msg, input_patient], output=[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_msg (InputLayer)           (None, 256, 1024, 16) 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 256, 1024, 96) 13920       input_msg[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 128, 256, 96)  0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 128, 256, 256) 221440      maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 64, 64, 256)   0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 64, 64, 512)   1180160     maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 32, 32, 512)   0           convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 32, 32, 512)   2359808     maxpooling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_4 (MaxPooling2D)    (None, 16, 16, 512)   0           convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)  (None, 16, 16, 512)   2359808     maxpooling2d_4[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_5 (MaxPooling2D)    (None, 8, 8, 512)     0           convolution2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 32768)         0           maxpooling2d_5[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "input_patient (InputLayer)       (None, 3)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_1 (Merge)                  (None, 32771)         0           flatten_1[0][0]                  \n",
      "                                                                   input_patient[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 2)             65544       merge_1[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 6200680\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "# del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils.visualize_util import plot\n",
    "plot(model, to_file='model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import gc\n",
    "\n",
    "scores = []\n",
    "\n",
    "def score_auc():\n",
    "    s = 0\n",
    "    n = len(X_val_msgs)\n",
    "    y_p = model.predict([X_val_msgs[s:s+n],\n",
    "                         X_val_patients[s:s+n]], \n",
    "                        verbose=False)\n",
    "    return metrics.roc_auc_score(y_val[s:s+n].T[0], y_p.T[0])\n",
    "\n",
    "class MyCallback(keras.callbacks.Callback):\n",
    "    def _validate(self):\n",
    "        s = score_auc()\n",
    "        scores.append(s)\n",
    "        print \"\\n\\n AUC = %.5f\\n\"%s; time.sleep(.5)\n",
    "    def on_train_begin(self, epoch, logs={}):\n",
    "        self._validate()\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self._validate()\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "def cb_shuffle_train_data(batch, logs):\n",
    "    global X_train_files, X_train_patients, y_train\n",
    "    X_train_files, X_train_patients, y_train = \\\n",
    "        shuffle(X_train_files, X_train_patients, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " AUC = 0.53111\n",
      "\n",
      "Epoch 1/111\n",
      "4256/4272 [============================>.] - ETA: 0s - loss: 1.4941 - acc: 0.9067\n",
      "\n",
      " AUC = 0.50000\n",
      "\n",
      "4272/4272 [==============================] - 266s - loss: 1.4923 - acc: 0.9068 - val_loss: 1.6467 - val_acc: 0.8973\n",
      "Epoch 2/111\n",
      "3744/4272 [=========================>....] - ETA: 27s - loss: 1.4686 - acc: 0.9084\n",
      "\n",
      " AUC = 0.50000\n",
      "\n",
      "4272/4272 [==============================] - 265s - loss: 1.4897 - acc: 0.9071 - val_loss: 1.6467 - val_acc: 0.8973\n",
      "Epoch 26/111\n",
      "4256/4272 [============================>.] - ETA: 0s - loss: 1.5330 - acc: 0.9044\n",
      "\n",
      " AUC = 0.50000\n",
      "\n",
      "4272/4272 [==============================] - 264s - loss: 1.5347 - acc: 0.9043 - val_loss: 1.6467 - val_acc: 0.8973\n",
      "Epoch 27/111\n",
      "4256/4272 [============================>.] - ETA: 0s - loss: 1.5066 - acc: 0.9060\n",
      "\n",
      " AUC = 0.50000\n",
      "\n",
      "4272/4272 [==============================] - 264s - loss: 1.5010 - acc: 0.9064 - val_loss: 1.6467 - val_acc: 0.8973\n",
      "Epoch 28/111\n",
      "4256/4272 [============================>.] - ETA: 0s - loss: 1.5480 - acc: 0.9034\n",
      "\n",
      " AUC = 0.50000\n",
      "\n",
      "4272/4272 [==============================] - 264s - loss: 1.5422 - acc: 0.9038 - val_loss: 1.6467 - val_acc: 0.8973\n",
      "Epoch 29/111\n",
      "4256/4272 [============================>.] - ETA: 0s - loss: 1.4652 - acc: 0.9086\n",
      "\n",
      " AUC = 0.50000\n",
      "\n",
      "4272/4272 [==============================] - 264s - loss: 1.4634 - acc: 0.9087 - val_loss: 1.6467 - val_acc: 0.8973\n",
      "Epoch 30/111\n",
      "4256/4272 [============================>.] - ETA: 0s - loss: 1.5028 - acc: 0.9062"
     ]
    }
   ],
   "source": [
    "# train\n",
    "hist = model.fit_generator(\n",
    "        train_generator(),\n",
    "        samples_per_epoch=TRAIN_N_SAMPLES_PER_EPOCH,\n",
    "        nb_epoch=TRAIN_N_EPOCHS,\n",
    "        validation_data=([X_val_msgs, X_val_patients], y_val),\n",
    "        verbose=True,\n",
    "        max_q_size=10,\n",
    "        nb_worker=1,\n",
    "        pickle_safe=False,\n",
    "        callbacks = [\n",
    "            MyCallback(),\n",
    "            LambdaCallback(\n",
    "                on_epoch_begin=cb_shuffle_train_data\n",
    "            ),\n",
    "            TensorBoard(log_dir=TFB_DIR, histogram_freq=0),\n",
    "            ModelCheckpoint(\n",
    "                MODELS_DIR + \\\n",
    "                '/e{epoch:02d}-l={loss:.5f}-vl={val_loss:.5f}-a={acc:.5f}-va={val_acc:.5f}.h5', \n",
    "                monitor='val_acc', verbose=0, save_best_only=False, \n",
    "                save_weights_only=False, mode='auto'\n",
    "            )\n",
    "        ]\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train\n",
    "# hist = model.fit([X_val_msgs, X_val_patients], y_val, batch_size=1, nb_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
