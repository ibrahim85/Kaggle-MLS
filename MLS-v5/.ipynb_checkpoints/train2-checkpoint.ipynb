{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RND = 123\n",
    "np.random.seed(RND)\n",
    "import random\n",
    "random.seed(RND)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "RUN = 'D'\n",
    "MODELS_DIR = '/d3/caches/kaggle-mls-v5/models/' + RUN\n",
    "TFB_DIR = '/tmp-persistent/mls5/' + RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOP_LEN 942\n"
     ]
    }
   ],
   "source": [
    "VAL_SIZE = 0.1\n",
    "\n",
    "MSGS_CACHE_DIR = 'out/msgs-256-processed'\n",
    "\n",
    "SAMPLING_RATE = 400\n",
    "N_SAMPLES = 240000\n",
    "N_CHANNELS = 16\n",
    "\n",
    "N_FFT=512\n",
    "N_MELS=256\n",
    "DESIRED_MSG_W = 256\n",
    "HOP_LEN = 1 + int(N_SAMPLES / (DESIRED_MSG_W - 1))\n",
    "\n",
    "WARM_CACHE = False\n",
    "\n",
    "print 'HOP_LEN', HOP_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make sure output dirs exist\n",
    "for v in [MSGS_CACHE_DIR, MODELS_DIR, TFB_DIR]: \n",
    "    if not os.path.isdir(v): \n",
    "        os.makedirs(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load inout files list\n",
    "input_df = pd.read_csv('out/input_files.csv', index_col='file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split inout files into train/test sets\n",
    "train_df = input_df[input_df['class'] != -1]\n",
    "test_df = input_df[input_df['class'] == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_trainval_files = train_df.index.tolist()\n",
    "X_trainval_patients = np.vstack((train_df['patient_1'], train_df['patient_2'], train_df['patient_3']))\\\n",
    "    .T.astype(np.float32)\n",
    "y_trainval = np.array(train_df['class'], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_batch(X_files=None, X_patients=None, y=None, start_ix=0, n_samples=1, \\\n",
    "              silent=True, compute_means=False, means_per_ch=None, div_by=None):\n",
    "    \n",
    "    X_msgs_batch = np.zeros((n_samples, N_MELS, DESIRED_MSG_W, N_CHANNELS), dtype=np.float32)\n",
    "    X_patients_batch = np.zeros((n_samples, X_patients.shape[1]), dtype=np.float32)        \n",
    "    y_batch = np.zeros([n_samples, 2], dtype=np.float32)\n",
    "    \n",
    "    if compute_means:\n",
    "        means = np.zeros([n_samples, N_CHANNELS], dtype=np.float32)\n",
    "    else:\n",
    "        means = None\n",
    "        \n",
    "    r = range(n_samples) if silent else tqdm(range(n_samples))\n",
    "\n",
    "    for i in r:\n",
    "        ii  = (i + start_ix) % len(X_files)\n",
    "        \n",
    "        mat_f = X_files[ii]\n",
    "        mat_cache_fp = MSGS_CACHE_DIR + '/' + mat_f + '.msgs.mem'\n",
    "        \n",
    "        # check if msgs are chached\n",
    "        if not os.path.isfile(mat_cache_fp):\n",
    "\n",
    "            mat_fp = input_df.ix[mat_f]['path']\n",
    "            waves = lib.read_mat(mat_fp)\n",
    "            \n",
    "            msgs = np.zeros((N_CHANNELS, N_MELS, DESIRED_MSG_W), dtype=np.float32)\n",
    "\n",
    "            for ch in range(16):\n",
    "                msgs[ch] = lib.compute_msg(waves[ch], \\\n",
    "                      desired_msg_w=DESIRED_MSG_W, hop_length=HOP_LEN, \\\n",
    "                      n_fft=N_FFT, n_mels=N_MELS, sr=SAMPLING_RATE)\n",
    "                            \n",
    "            # move channel axis, shape is now: (ix, h, w, ch)\n",
    "            msgs_t = np.swapaxes(msgs, 0, 1)\n",
    "            msgs_t = np.swapaxes(msgs_t, 1, 2)\n",
    "\n",
    "            X_msgs_batch[i] = msgs_t\n",
    "            \n",
    "            if not means_per_ch is None:\n",
    "                X_msgs_batch = np.subtract(X_msgs_batch, means_per_ch)\n",
    "\n",
    "            if not div_by is None:\n",
    "                X_msgs_batch = np.divide(X_msgs_batch, div_by)\n",
    "                \n",
    "            # save to cache\n",
    "            X_msgs_batch[i].tofile(mat_cache_fp)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            X_msgs_batch[i] = np.fromfile(mat_cache_fp, dtype=np.float32).\\\n",
    "                reshape((N_MELS, DESIRED_MSG_W, N_CHANNELS))\n",
    "                \n",
    "        # compute means\n",
    "        if compute_means:\n",
    "            means[i] = np.mean(X_msgs_batch.T.reshape(N_CHANNELS, -1), axis=1)\n",
    "\n",
    "        X_patients_batch[i] = X_patients[ii]\n",
    "        y_batch[i] = [1., 0.] if y[ii] else [0., 1.]\n",
    "            \n",
    "    return X_msgs_batch, X_patients_batch, y_batch, means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# warm cache\n",
    "if WARM_CACHE:\n",
    "    \n",
    "    means = []\n",
    "    \n",
    "    means_per_ch = np.load('out/means_per_ch.npy')\n",
    "\n",
    "    X_files = input_df.index.tolist()\n",
    "    X_patients = np.vstack((input_df['patient_1'], input_df['patient_2'], input_df['patient_3']))\\\n",
    "        .T.astype(np.float32)\n",
    "    y = np.zeros((len(X_files), 1), dtype=np.float32)\n",
    "    \n",
    "    start = 0\n",
    "    stop = len(X_files)\n",
    "\n",
    "    for i in tqdm(xrange(start, stop)):\n",
    "        _msgs, _patients, _ys, _means = \\\n",
    "            gen_batch(X_files, X_patients, y, start_ix=i, n_samples=1, \\\n",
    "                      silent=True, compute_means=True, \\\n",
    "                     means_per_ch=means_per_ch, div_by=255.)\n",
    "#         means.append(_means[0])\n",
    "\n",
    "#     means_per_ch = np.mean(means, axis=0)\n",
    "#     np.save('out/means_per_ch.npy', means_per_ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_N_PER_BATCH = 16\n",
    "TRAIN_N_EPOCHS = 111"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_ix = 0\n",
    "    \n",
    "# training data generator\n",
    "def train_generator():\n",
    "\n",
    "    global start_ix\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        b = gen_batch(\n",
    "            X_train_files, X_train_patients, y_train, \n",
    "            start_ix=start_ix, n_samples=TRAIN_N_PER_BATCH\n",
    "        )\n",
    "                \n",
    "        start_ix += TRAIN_N_SAMPLES_PER_EPOCH\n",
    "        \n",
    "        yield [b[0], b[1]], b[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import *\n",
    "from keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_msg = Input(shape=(N_MELS, DESIRED_MSG_W, N_CHANNELS), name='input_msg')\n",
    "\n",
    "x = Convolution2D(64, 3, 3, border_mode='same', activation='relu')(input_msg)\n",
    "x = Convolution2D(64, 3, 3, border_mode='same', activation='relu')(x)\n",
    "x = MaxPooling2D((2, 2), strides=(2, 2))(x)\n",
    "\n",
    "x = Convolution2D(128, 3, 3, border_mode='same', activation='relu')(x)\n",
    "x = Convolution2D(128, 3, 3, border_mode='same', activation='relu')(x)\n",
    "x = MaxPooling2D((2, 2), strides=(2, 2))(x)\n",
    "\n",
    "x = Convolution2D(256, 3, 3, border_mode='same', activation='relu')(x)\n",
    "x = Convolution2D(256, 3, 3, border_mode='same', activation='relu')(x)\n",
    "x = MaxPooling2D((2, 2), strides=(2, 2))(x)\n",
    "\n",
    "x = Convolution2D(512, 3, 3, border_mode='same', activation='relu')(x)\n",
    "x = Convolution2D(512, 3, 3, border_mode='same', activation='relu')(x)\n",
    "x = MaxPooling2D((2, 2), strides=(2, 2))(x)\n",
    "\n",
    "x = Convolution2D(512, 3, 3, border_mode='same', activation='relu')(x)\n",
    "x = Convolution2D(512, 3, 3, border_mode='same', activation='relu')(x)\n",
    "x = MaxPooling2D((2, 2), strides=(2, 2))(x)\n",
    "\n",
    "x = Convolution2D(512, 3, 3, border_mode='same', activation='relu')(x)\n",
    "x = Convolution2D(512, 3, 3, border_mode='same', activation='relu')(x)\n",
    "x = MaxPooling2D((2, 2), strides=(2, 2))(x)\n",
    "\n",
    "conv_out = Flatten()(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_patient = Input(shape=(3,), name='input_patient')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = merge([conv_out, input_patient], mode='concat')\n",
    "x = Dense(2, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model(input=[input_msg, input_patient], output=[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='SGD', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_msg (InputLayer)           (None, 256, 256, 16)  0                                            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 256, 256, 64)  9280        input_msg[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 256, 256, 64)  36928       convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 128, 128, 64)  0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 128, 128, 128) 73856       maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 128, 128, 128) 147584      convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 64, 64, 128)   0           convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)  (None, 64, 64, 256)   295168      maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_6 (Convolution2D)  (None, 64, 64, 256)   590080      convolution2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 32, 32, 256)   0           convolution2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_7 (Convolution2D)  (None, 32, 32, 512)   1180160     maxpooling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_8 (Convolution2D)  (None, 32, 32, 512)   2359808     convolution2d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_4 (MaxPooling2D)    (None, 16, 16, 512)   0           convolution2d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_9 (Convolution2D)  (None, 16, 16, 512)   2359808     maxpooling2d_4[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_10 (Convolution2D) (None, 16, 16, 512)   2359808     convolution2d_9[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_5 (MaxPooling2D)    (None, 8, 8, 512)     0           convolution2d_10[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_11 (Convolution2D) (None, 8, 8, 512)     2359808     maxpooling2d_5[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_12 (Convolution2D) (None, 8, 8, 512)     2359808     convolution2d_11[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_6 (MaxPooling2D)    (None, 4, 4, 512)     0           convolution2d_12[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 8192)          0           maxpooling2d_6[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "input_patient (InputLayer)       (None, 3)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_1 (Merge)                  (None, 8195)          0           flatten_1[0][0]                  \n",
      "                                                                   input_patient[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 2)             16392       merge_1[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 14148488\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "# del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils.visualize_util import plot\n",
    "plot(model, to_file='model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import gc\n",
    "\n",
    "scores = []\n",
    "\n",
    "def score_auc():\n",
    "    s = 0\n",
    "    n = len(X_val_msgs)\n",
    "    y_p = model.predict([X_val_msgs[s:s+n],\n",
    "                         X_val_patients[s:s+n]], \n",
    "                        verbose=False)\n",
    "    return metrics.roc_auc_score(y_val[s:s+n].T[0], y_p.T[0])\n",
    "\n",
    "class MyCallback(keras.callbacks.Callback):\n",
    "    def _validate(self):\n",
    "        s = score_auc()\n",
    "        scores.append(s)\n",
    "        print \"\\n\\n AUC = %.5f\\n\"%s; time.sleep(.5)\n",
    "    def on_train_begin(self, epoch, logs={}):\n",
    "        self._validate()\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self._validate()\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "def cb_shuffle_train_data(batch, logs):\n",
    "    global X_train_files, X_train_patients, y_train\n",
    "    X_train_files, X_train_patients, y_train = \\\n",
    "        shuffle(X_train_files, X_train_patients, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 1621/4764 [00:22<00:42, 73.33it/s]"
     ]
    }
   ],
   "source": [
    "# generate trainval set\n",
    "X_trainval_msgs, X_trainval_patients, y_trainval, _means = \\\n",
    "    gen_batch(X_trainval_files, X_trainval_patients, y_trainval, \\\n",
    "                n_samples=len(X_trainval_files), silent=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'Memory for trainval set: %.2fG' % (X_trainval_msgs.size * 4. / pow(2, 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_msgs, X_val_msgs, X_train_patients, X_val_patients, y_train, y_val = \\\n",
    "    train_test_split(X_trainval_msgs, X_trainval_patients, y_trainval, random_state=RND, test_size=VAL_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del X_trainval_msgs\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3573 samples, validate on 1191 samples\n",
      "Epoch 1/111\n",
      "2688/3573 [=====================>........] - ETA: 36s - loss: 0.4026 - acc: 0.9040"
     ]
    }
   ],
   "source": [
    "# train\n",
    "hist = model.fit(\n",
    "        [X_train_msgs, X_train_patients],\n",
    "        y_train,\n",
    "        batch_size=TRAIN_N_PER_BATCH,\n",
    "        nb_epoch=TRAIN_N_EPOCHS,\n",
    "#         validation_split=0.2,\n",
    "        validation_data=([X_val_msgs, X_val_patients], y_val),\n",
    "        verbose=True,\n",
    "        shuffle=True,\n",
    "        callbacks = [\n",
    "            MyCallback(),\n",
    "            TensorBoard(log_dir=TFB_DIR, histogram_freq=0),\n",
    "            ModelCheckpoint(\n",
    "                MODELS_DIR + \\\n",
    "                '/e{epoch:02d}-l={loss:.5f}-vl={val_loss:.5f}-a={acc:.5f}-va={val_acc:.5f}.h5', \n",
    "                monitor='val_acc', verbose=0, save_best_only=False, \n",
    "                save_weights_only=False, mode='auto'\n",
    "            )\n",
    "        ]\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(X_trainval_patients)):\n",
    "    X_trainval_patients[i,:] = y_trainval[i][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 1.,  1.,  1.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trainval_patients[:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_trainval[:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_msg\n",
      "convolution2d_1\n",
      "convolution2d_2\n",
      "maxpooling2d_1\n",
      "convolution2d_3\n",
      "convolution2d_4\n",
      "maxpooling2d_2\n",
      "convolution2d_5\n",
      "convolution2d_6\n",
      "maxpooling2d_3\n",
      "convolution2d_7\n",
      "convolution2d_8\n",
      "maxpooling2d_4\n",
      "convolution2d_9\n",
      "convolution2d_10\n",
      "maxpooling2d_5\n"
     ]
    }
   ],
   "source": [
    "for l in model.layers[:16]:\n",
    "    print l.name\n",
    "    l.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
