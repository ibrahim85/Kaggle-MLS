{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.io import loadmat\n",
    "from operator import itemgetter\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "import glob\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random.seed(777)\n",
    "np.random.seed(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_feature_map(features):\n",
    "    outfile = open('xgb.fmap', 'w')\n",
    "    for i, feat in enumerate(features):\n",
    "        outfile.write('{0}\\t{1}\\tq\\n'.format(i, feat))\n",
    "    outfile.close()\n",
    "\n",
    "\n",
    "def get_importance(gbm, features):\n",
    "    create_feature_map(features)\n",
    "    importance = gbm.get_fscore(fmap='xgb.fmap')\n",
    "    importance = sorted(importance.items(), key=itemgetter(1), reverse=True)\n",
    "    return importance\n",
    "\n",
    "\n",
    "def intersect(a, b):\n",
    "    return list(set(a) & set(b))\n",
    "\n",
    "\n",
    "def print_features_importance(imp):\n",
    "    for i in range(len(imp)):\n",
    "        print(\"# \" + str(imp[i][1]))\n",
    "        print('output.remove(\\'' + imp[i][0] + '\\')')\n",
    "\n",
    "\n",
    "def mat_to_pandas(path):\n",
    "    mat = loadmat(path)\n",
    "    names = mat['dataStruct'].dtype.names\n",
    "    ndata = {n: mat['dataStruct'][n][0, 0] for n in names}\n",
    "    return pd.DataFrame(ndata['data'], columns=ndata['channelIndices'][0])\n",
    "\n",
    "\n",
    "def create_simple_csv():\n",
    "    # TRAIN\n",
    "    print('Create train.csv...')\n",
    "    files = sorted(glob.glob(\"/datasets/kaggle/mls/train_*/*.mat\"))\n",
    "    out = open(\"simple_train.csv\", \"w\")\n",
    "    out.write(\"Id,patient_id\")\n",
    "    for i in range(16):\n",
    "        out.write(\",avg_\" + str(i))\n",
    "    out.write(\",file_size,result\\n\")\n",
    "    \n",
    "    \n",
    "    for fl in tqdm(files):\n",
    "        \n",
    "        # print('Go for ' + fl)\n",
    "        id_str = os.path.basename(fl)[:-4]\n",
    "        arr = id_str.split(\"_\")\n",
    "        patient = int(arr[0])\n",
    "        id = int(arr[1])\n",
    "        result = int(arr[2])\n",
    "        new_id = patient*100000 + id\n",
    "        try:\n",
    "            tables = mat_to_pandas(fl)\n",
    "        except:\n",
    "            continue\n",
    "        out.write(str(new_id))\n",
    "        out.write(\",\" + str(patient))\n",
    "        for f in sorted(list(tables.columns.values)):\n",
    "            mean = tables[f].mean()\n",
    "            out.write(\",\" + str(mean))\n",
    "        out.write(\",\" + str(os.path.getsize(fl)))\n",
    "        out.write(\",\" + str(result) + \"\\n\")\n",
    "        # break\n",
    "        \n",
    "    out.close()\n",
    "\n",
    "    # TEST\n",
    "    print('Create test.csv...')\n",
    "    files = sorted(glob.glob(\"/datasets/kaggle/mls/test_*/*.mat\"))\n",
    "    out = open(\"simple_test.csv\", \"w\")\n",
    "    out.write(\"Id,patient_id\")\n",
    "    for i in range(16):\n",
    "        out.write(\",avg_\" + str(i))\n",
    "    out.write(\",file_size\\n\")\n",
    "    \n",
    "    for fl in tqdm(files):\n",
    "        # print('Go for ' + fl)\n",
    "        id_str = os.path.basename(fl)[:-4]\n",
    "        arr = id_str.split(\"_\")\n",
    "        patient = int(arr[0])\n",
    "        id = int(arr[1])\n",
    "        new_id = patient*100000 + id\n",
    "        try:\n",
    "            tables = mat_to_pandas(fl)\n",
    "        except:\n",
    "            continue\n",
    "        out.write(str(new_id))\n",
    "        out.write(\",\" + str(patient))\n",
    "        for f in sorted(list(tables.columns.values)):\n",
    "            mean = tables[f].mean()\n",
    "            out.write(\",\" + str(mean))\n",
    "        out.write(\",\" + str(os.path.getsize(fl)))\n",
    "        out.write(\"\\n\")\n",
    "        # break\n",
    "    out.close()\n",
    "\n",
    "\n",
    "def run_single(train, test, features, target, random_state=1):\n",
    "    eta = 0.1\n",
    "    max_depth = 5\n",
    "    subsample = 0.92\n",
    "    colsample_bytree = 0.9\n",
    "    start_time = time.time()\n",
    "\n",
    "    print('XGBoost params. ETA: {}, MAX_DEPTH: {}, SUBSAMPLE: {}, COLSAMPLE_BY_TREE: {}'.format(eta, max_depth, subsample, colsample_bytree))\n",
    "    params = {\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"booster\" : \"gbtree\",\n",
    "        \"eval_metric\": \"auc\",\n",
    "        \"eta\": eta,\n",
    "        \"tree_method\": 'exact',\n",
    "        \"max_depth\": max_depth,\n",
    "        \"subsample\": subsample,\n",
    "        \"colsample_bytree\": colsample_bytree,\n",
    "        \"silent\": 1,\n",
    "        \"seed\": random_state,\n",
    "    }\n",
    "    num_boost_round = 1000\n",
    "    early_stopping_rounds = 50\n",
    "    test_size = 0.2\n",
    "\n",
    "    kf = KFold(len(train.index), n_folds=int(round(1/test_size, 0)), shuffle=True, random_state=random_state)\n",
    "    train_index, test_index = list(kf)[0]\n",
    "    print('Length of train: {}'.format(len(train_index)))\n",
    "    print('Length of valid: {}'.format(len(test_index)))\n",
    "\n",
    "    X_train, X_valid = train[features].as_matrix()[train_index], train[features].as_matrix()[test_index]\n",
    "    y_train, y_valid = train[target].as_matrix()[train_index], train[target].as_matrix()[test_index]\n",
    "\n",
    "    print('Length train:', len(X_train))\n",
    "    print('Length valid:', len(X_valid))\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_train, y_train)\n",
    "    dvalid = xgb.DMatrix(X_valid, y_valid)\n",
    "\n",
    "    watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "    gbm = xgb.train(params, dtrain, num_boost_round, evals=watchlist,\n",
    "                    early_stopping_rounds=early_stopping_rounds, verbose_eval=True)\n",
    "\n",
    "    print(\"Validating...\")\n",
    "    check = gbm.predict(xgb.DMatrix(X_valid), ntree_limit=gbm.best_iteration+1)\n",
    "    score = roc_auc_score(y_valid, check)\n",
    "    print('Check error value: {:.6f}'.format(score))\n",
    "\n",
    "    imp = get_importance(gbm, features)\n",
    "    print('Importance array: ', imp)\n",
    "\n",
    "    print(\"Predict test set...\")\n",
    "    test_prediction = gbm.predict(xgb.DMatrix(test[features].as_matrix()), ntree_limit=gbm.best_iteration+1)\n",
    "\n",
    "    print('Training time: {} minutes'.format(round((time.time() - start_time)/60, 2)))\n",
    "    return test_prediction.tolist(), score\n",
    "\n",
    "\n",
    "def create_submission(score, test, prediction):\n",
    "    # Make Submission\n",
    "    now = datetime.datetime.now()\n",
    "    sub_file = 'submission_' + str(score) + '_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "    print('Writing submission: ', sub_file)\n",
    "    f = open(sub_file, 'w')\n",
    "    f.write('File,Class\\n')\n",
    "    total = 0\n",
    "    for id in test['Id']:\n",
    "        patient = id // 100000\n",
    "        fid = id % 100000\n",
    "        str1 = str(patient) + '_' + str(fid) + '.mat' + ',' + str(prediction[total])\n",
    "        str1 += '\\n'\n",
    "        total += 1\n",
    "        f.write(str1)\n",
    "    f.close()\n",
    "\n",
    "\n",
    "def get_features(train, test):\n",
    "    trainval = list(train.columns.values)\n",
    "    testval = list(test.columns.values)\n",
    "    output = intersect(trainval, testval)\n",
    "    output.remove('Id')\n",
    "    # output.remove('file_size')\n",
    "    return sorted(output)\n",
    "\n",
    "\n",
    "def read_test_train():\n",
    "    print(\"Load train.csv...\")\n",
    "    train = pd.read_csv(\"simple_train.csv\")\n",
    "    print(\"Load test.csv...\")\n",
    "    test = pd.read_csv(\"simple_test.csv\")\n",
    "    print(\"Process tables...\")\n",
    "    features = get_features(train, test)\n",
    "    return train, test, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/6042 [00:00<09:04, 11.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost: 0.6\n",
      "Create train.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6042/6042 [07:51<00:00, 12.83it/s]\n",
      "  0%|          | 2/6126 [00:00<08:17, 12.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create test.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6126/6126 [08:05<00:00, 12.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load train.csv...\n",
      "Load test.csv...\n",
      "Process tables...\n",
      "('Length of train: ', 6042)\n",
      "('Length of test: ', 6126)\n",
      "Features [18]: ['avg_0', 'avg_1', 'avg_10', 'avg_11', 'avg_12', 'avg_13', 'avg_14', 'avg_15', 'avg_2', 'avg_3', 'avg_4', 'avg_5', 'avg_6', 'avg_7', 'avg_8', 'avg_9', 'file_size', 'patient_id']\n",
      "XGBoost params. ETA: 0.1, MAX_DEPTH: 5, SUBSAMPLE: 0.92, COLSAMPLE_BY_TREE: 0.9\n",
      "Length of train: 4833\n",
      "Length of valid: 1209\n",
      "('Length train:', 4833)\n",
      "('Length valid:', 1209)\n",
      "[0]\ttrain-auc:0.699582\teval-auc:0.648061\n",
      "Multiple eval metrics have been passed: 'eval-auc' will be used for early stopping.\n",
      "\n",
      "Will train until eval-auc hasn't improved in 50 rounds.\n",
      "[1]\ttrain-auc:0.710219\teval-auc:0.661985\n",
      "[2]\ttrain-auc:0.720333\teval-auc:0.664607\n",
      "[3]\ttrain-auc:0.760721\teval-auc:0.689907\n",
      "[4]\ttrain-auc:0.764542\teval-auc:0.686532\n",
      "[5]\ttrain-auc:0.771819\teval-auc:0.692639\n",
      "[6]\ttrain-auc:0.790394\teval-auc:0.691865\n",
      "[7]\ttrain-auc:0.794618\teval-auc:0.692567\n",
      "[8]\ttrain-auc:0.80774\teval-auc:0.695791\n",
      "[9]\ttrain-auc:0.814705\teval-auc:0.70818\n",
      "[10]\ttrain-auc:0.827786\teval-auc:0.713872\n",
      "[11]\ttrain-auc:0.83916\teval-auc:0.723131\n",
      "[12]\ttrain-auc:0.842934\teval-auc:0.724371\n",
      "[13]\ttrain-auc:0.844972\teval-auc:0.724675\n",
      "[14]\ttrain-auc:0.851967\teval-auc:0.727506\n",
      "[15]\ttrain-auc:0.853954\teval-auc:0.726325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16]\ttrain-auc:0.857488\teval-auc:0.724337\n",
      "[17]\ttrain-auc:0.860313\teval-auc:0.724833\n",
      "[18]\ttrain-auc:0.864425\teval-auc:0.724499\n",
      "[19]\ttrain-auc:0.869881\teval-auc:0.726903\n",
      "[20]\ttrain-auc:0.874083\teval-auc:0.730995\n",
      "[21]\ttrain-auc:0.879538\teval-auc:0.733305\n",
      "[22]\ttrain-auc:0.884549\teval-auc:0.738607\n",
      "[23]\ttrain-auc:0.885576\teval-auc:0.740472\n",
      "[24]\ttrain-auc:0.888196\teval-auc:0.742508\n",
      "[25]\ttrain-auc:0.893557\teval-auc:0.743615\n",
      "[26]\ttrain-auc:0.898833\teval-auc:0.744445\n",
      "[27]\ttrain-auc:0.900213\teval-auc:0.744193\n",
      "[28]\ttrain-auc:0.900373\teval-auc:0.743363\n",
      "[29]\ttrain-auc:0.904425\teval-auc:0.742841\n",
      "[30]\ttrain-auc:0.908011\teval-auc:0.742148\n",
      "[31]\ttrain-auc:0.910449\teval-auc:0.742328\n",
      "[32]\ttrain-auc:0.913576\teval-auc:0.745446\n",
      "[33]\ttrain-auc:0.91465\teval-auc:0.745026\n",
      "[34]\ttrain-auc:0.917721\teval-auc:0.74616\n",
      "[35]\ttrain-auc:0.919991\teval-auc:0.745116\n",
      "[36]\ttrain-auc:0.920405\teval-auc:0.744364\n",
      "[37]\ttrain-auc:0.921932\teval-auc:0.74273\n",
      "[38]\ttrain-auc:0.923446\teval-auc:0.741858\n",
      "[39]\ttrain-auc:0.925498\teval-auc:0.744971\n",
      "[40]\ttrain-auc:0.928756\teval-auc:0.744312\n",
      "[41]\ttrain-auc:0.930925\teval-auc:0.743743\n",
      "[42]\ttrain-auc:0.931796\teval-auc:0.741494\n",
      "[43]\ttrain-auc:0.933434\teval-auc:0.739313\n",
      "[44]\ttrain-auc:0.933942\teval-auc:0.739467\n",
      "[45]\ttrain-auc:0.935228\teval-auc:0.736662\n",
      "[46]\ttrain-auc:0.936465\teval-auc:0.736961\n",
      "[47]\ttrain-auc:0.938349\teval-auc:0.737859\n",
      "[48]\ttrain-auc:0.940106\teval-auc:0.736585\n",
      "[49]\ttrain-auc:0.940948\teval-auc:0.736063\n",
      "[50]\ttrain-auc:0.943678\teval-auc:0.737868\n",
      "[51]\ttrain-auc:0.944557\teval-auc:0.738107\n",
      "[52]\ttrain-auc:0.946994\teval-auc:0.737611\n",
      "[53]\ttrain-auc:0.947915\teval-auc:0.739236\n",
      "[54]\ttrain-auc:0.950035\teval-auc:0.738838\n",
      "[55]\ttrain-auc:0.950345\teval-auc:0.740959\n",
      "[56]\ttrain-auc:0.952704\teval-auc:0.741421\n",
      "[57]\ttrain-auc:0.953757\teval-auc:0.742371\n",
      "[58]\ttrain-auc:0.956514\teval-auc:0.74409\n",
      "[59]\ttrain-auc:0.958508\teval-auc:0.74249\n",
      "[60]\ttrain-auc:0.958747\teval-auc:0.743192\n",
      "[61]\ttrain-auc:0.960685\teval-auc:0.74285\n",
      "[62]\ttrain-auc:0.962454\teval-auc:0.74131\n",
      "[63]\ttrain-auc:0.963065\teval-auc:0.741387\n",
      "[64]\ttrain-auc:0.964358\teval-auc:0.740814\n",
      "[65]\ttrain-auc:0.96531\teval-auc:0.738736\n",
      "[66]\ttrain-auc:0.966583\teval-auc:0.738873\n",
      "[67]\ttrain-auc:0.967984\teval-auc:0.737915\n",
      "[68]\ttrain-auc:0.96958\teval-auc:0.739198\n",
      "[69]\ttrain-auc:0.97038\teval-auc:0.738513\n",
      "[70]\ttrain-auc:0.970442\teval-auc:0.739437\n",
      "[71]\ttrain-auc:0.971041\teval-auc:0.738453\n",
      "[72]\ttrain-auc:0.971394\teval-auc:0.738094\n",
      "[73]\ttrain-auc:0.971572\teval-auc:0.739044\n",
      "[74]\ttrain-auc:0.972085\teval-auc:0.73942\n",
      "[75]\ttrain-auc:0.973608\teval-auc:0.739446\n",
      "[76]\ttrain-auc:0.975959\teval-auc:0.73995\n",
      "[77]\ttrain-auc:0.976552\teval-auc:0.74054\n",
      "[78]\ttrain-auc:0.97695\teval-auc:0.740361\n",
      "[79]\ttrain-auc:0.978008\teval-auc:0.740729\n",
      "[80]\ttrain-auc:0.978637\teval-auc:0.742525\n",
      "[81]\ttrain-auc:0.980187\teval-auc:0.741917\n",
      "[82]\ttrain-auc:0.980491\teval-auc:0.741302\n",
      "[83]\ttrain-auc:0.98076\teval-auc:0.741644\n",
      "[84]\ttrain-auc:0.981045\teval-auc:0.7406\n",
      "Stopping. Best iteration:\n",
      "[34]\ttrain-auc:0.917721\teval-auc:0.74616\n",
      "\n",
      "Validating...\n",
      "Check error value: 0.746160\n",
      "('Importance array: ', [('avg_4', 149), ('file_size', 120), ('avg_0', 113), ('avg_2', 111), ('avg_7', 104), ('avg_3', 102), ('avg_12', 96), ('avg_6', 96), ('avg_9', 94), ('avg_1', 93), ('avg_11', 90), ('avg_5', 90), ('avg_13', 85), ('avg_8', 80), ('avg_15', 60), ('avg_14', 59), ('avg_10', 41), ('patient_id', 4)])\n",
      "Predict test set...\n",
      "Training time: 0.01 minutes\n",
      "('Writing submission: ', 'submission_0.746159701671_2016-10-19-17-44.csv')\n"
     ]
    }
   ],
   "source": [
    "print('XGBoost: {}'.format(xgb.__version__))\n",
    "# create_simple_csv()\n",
    "train, test, features = read_test_train()\n",
    "print('Length of train: ', len(train))\n",
    "print('Length of test: ', len(test))\n",
    "print('Features [{}]: {}'.format(len(features), sorted(features)))\n",
    "test_prediction, score = run_single(train, test, features, 'result')\n",
    "create_submission(score, test, test_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
