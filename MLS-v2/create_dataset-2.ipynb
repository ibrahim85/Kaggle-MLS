{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import keras\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RND_SEED = 777\n",
    "\n",
    "MSGS_DIR = 'out/msgs'\n",
    "\n",
    "MSG_SHAPE_IN = (16, 16, 64)\n",
    "# MSG_SHAPE_OUT = (96, 2048, 16)\n",
    "MSG_SHAPE_OUT = (16, 16, 64, 1)\n",
    "\n",
    "TRAIN_SAMPLES_PER_FILE = 10000\n",
    "TRAIN_FILE = 'out/train-msgs-%d.mem'\n",
    "TRAIN_YS_FILE = 'out/train-ys-%d.npy'\n",
    "TRAIN_PATS_FILE = 'out/train-pats-%d.npy'\n",
    "\n",
    "VALIDATION_SIZE = 1000\n",
    "VALIDATION_FILE = 'out/val-msgs.mem'\n",
    "VALIDATION_YS_FILE = 'out/val-ys.npy'\n",
    "VALIDATION_PATS_FILE = 'out/val-pats.npy'\n",
    "\n",
    "PATIENT_FEATURES = {\n",
    "    '1': [1., 0., 0.],\n",
    "    '2': [0., 1., 0.],\n",
    "    '3': [0., 0., 1.]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 16, 16, 64, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1,) + MSG_SHAPE_OUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(RND_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# list files in directories\n",
    "def list_files(src_dirs):\n",
    "\n",
    "    if not list == type(src_dirs): src_dirs = [src_dirs]\n",
    "    \n",
    "    f = []\n",
    "    \n",
    "    for d in src_dirs:\n",
    "        df = []\n",
    "        for (dirpath, dirnames, filenames) in os.walk(d):\n",
    "            filenames = [dirpath + '/' + x for x in filenames]\n",
    "            df.extend(filenames)\n",
    "        f.extend(df)\n",
    "    \n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12168/12168 [00:00<00:00, 523938.15it/s]\n"
     ]
    }
   ],
   "source": [
    "# create list of fids+ys for training\n",
    "train_items = []\n",
    "\n",
    "for f in tqdm(list_files(MSGS_DIR)):\n",
    "    \n",
    "    m = re.findall(r'(\\d+)_(\\d+)_(\\d+)\\.npy$', f)\n",
    "    \n",
    "    if len(m) > 0:\n",
    "        fid = \"%s_%s_%s\"%(m[0])\n",
    "        y = float(m[0][-1])\n",
    "        patient = m[0][0]\n",
    "        train_items.append([fid, y, patient])\n",
    "        \n",
    "np.random.shuffle(train_items)\n",
    "# train_items = np.array(train_items, dtype=np.object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training items: 6042 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create dataset files\n",
    "print 'Total training items:', len(train_items), '\\n'; time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 4665.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flushing... \n",
      "Created  out/val-msgs.mem out/val-ys.npy out/val-pats.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5042/5042 [00:01<00:00, 4795.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flushing... \n",
      "Created  out/train-msgs-1.mem out/train-ys-1.npy out/train-pats-1.npy\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "validation_set_created = False\n",
    "\n",
    "while len(train_items):\n",
    "\n",
    "    if validation_set_created:\n",
    "        i += 1\n",
    "        data_f = TRAIN_FILE%(i)\n",
    "        ys_f = TRAIN_YS_FILE%(i)\n",
    "        pats_f = TRAIN_PATS_FILE%(i)\n",
    "        portion = train_items[:TRAIN_SAMPLES_PER_FILE]\n",
    "        train_items = train_items[TRAIN_SAMPLES_PER_FILE:]\n",
    "    else:\n",
    "        portion = train_items[:VALIDATION_SIZE]\n",
    "        train_items = train_items[VALIDATION_SIZE:]\n",
    "        data_f = VALIDATION_FILE\n",
    "        ys_f = VALIDATION_YS_FILE\n",
    "        pats_f = VALIDATION_PATS_FILE\n",
    "        validation_set_created = True\n",
    "    \n",
    "    samples = np.memmap(\n",
    "        data_f, \n",
    "        dtype=np.float32, \n",
    "        mode='w+', \n",
    "        shape=(len(portion),) + MSG_SHAPE_OUT\n",
    "    )\n",
    "    \n",
    "    ys = np.zeros([len(portion), 2], dtype=np.float32)\n",
    "    pats = np.zeros([len(portion), 3], dtype=np.float32)\n",
    "    \n",
    "    s = 0\n",
    "\n",
    "    for x in tqdm(portion):\n",
    "        fid = x[0]\n",
    "        y = [x[1], 1. - x[1]]\n",
    "        p = PATIENT_FEATURES[x[2]]\n",
    "        d = np.load(MSGS_DIR + '/' + fid + '.npy').reshape(MSG_SHAPE_OUT)\n",
    "        samples[s] = d\n",
    "        ys[s] = y\n",
    "        pats[s] = p\n",
    "        s += 1\n",
    "        \n",
    "    print 'flushing... '\n",
    "    samples.flush()\n",
    "    \n",
    "    np.save(ys_f, ys)\n",
    "    np.save(pats_f, pats)\n",
    "\n",
    "    print 'Created ', data_f, ys_f, pats_f; time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80672"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load('out/train-ys-1.npy').shape[0] * 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80672"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples.shape[0] * 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.fromfile()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
