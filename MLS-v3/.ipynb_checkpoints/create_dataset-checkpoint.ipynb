{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python2.7/dist-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import keras\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RND_SEED = 777\n",
    "\n",
    "BOTTLENECKS_DIR = 'out/bottlenecks'\n",
    "\n",
    "SAMPLE_SIZE = 3 + 16 * 32\n",
    "\n",
    "TRAIN_SAMPLES_PER_FILE = 10000\n",
    "TRAIN_FILE = 'out/train-samples-%d.mem'\n",
    "TRAIN_YS_FILE = 'out/train-ys-%d.npy'\n",
    "\n",
    "VALIDATION_SIZE = 604\n",
    "VALIDATION_FILE = 'out/val-samples.mem'\n",
    "VALIDATION_YS_FILE = 'out/val-ys.mem'\n",
    "\n",
    "PATIENTS_ENCODING = {\n",
    "    '1': [1.,0.,0.],\n",
    "    '2': [0.,1.,0.],\n",
    "    '3': [0.,0.,1.]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(RND_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# list files in directories\n",
    "def list_files(src_dirs):\n",
    "\n",
    "    if not list == type(src_dirs): src_dirs = [src_dirs]\n",
    "    \n",
    "    f = []\n",
    "    \n",
    "    for d in src_dirs:\n",
    "        df = []\n",
    "        for (dirpath, dirnames, filenames) in os.walk(d):\n",
    "            filenames = [dirpath + '/' + x for x in filenames]\n",
    "            df.extend(filenames)\n",
    "        f.extend(df)\n",
    "    \n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12168/12168 [00:00<00:00, 355156.13it/s]\n"
     ]
    }
   ],
   "source": [
    "# create list of fids+ys for training\n",
    "train_items = []\n",
    "eval_items = []\n",
    "\n",
    "for f in tqdm(list_files(BOTTLENECKS_DIR)):\n",
    "    \n",
    "    m = re.findall(r'((\\d+)_(\\d+)(?:_(\\d))?)\\.npy$', f)\n",
    "    fid = m[0][0]\n",
    "    patient = m[0][1]\n",
    "    \n",
    "    if m[0][3] == '':\n",
    "        # test\n",
    "        eval_items.append({'fid': fid, 'patient': patient})\n",
    "    else:\n",
    "        # train\n",
    "        y = float(m[0][3])\n",
    "        train_items.append({'fid': fid, 'y': y, 'patient': patient})\n",
    "        \n",
    "np.random.shuffle(train_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create dataset files\n",
    "print 'Total training items:', len(train_items), '\\n'\n",
    "print 'Total eval items:', len(eval_items), '\\n'; time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 604/604 [00:00<00:00, 5873.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flushing... \n",
      "Created  out/val-msgs.mem out/val-ys.mem\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5438/5438 [00:00<00:00, 5882.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flushing... \n",
      "Created  out/train-msgs-1.mem out/train-ys-1.npy\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "validation_set_created = False\n",
    "\n",
    "while len(train_items):\n",
    "\n",
    "    if validation_set_created:\n",
    "        i += 1\n",
    "        data_f = TRAIN_FILE%(i)\n",
    "        ys_f = TRAIN_YS_FILE%(i)\n",
    "        portion = train_items[:TRAIN_SAMPLES_PER_FILE]\n",
    "        train_items = train_items[TRAIN_SAMPLES_PER_FILE:]\n",
    "    else:\n",
    "        portion = train_items[:VALIDATION_SIZE]\n",
    "        train_items = train_items[VALIDATION_SIZE:]\n",
    "        data_f = VALIDATION_FILE\n",
    "        ys_f = VALIDATION_YS_FILE\n",
    "        validation_set_created = True\n",
    "    \n",
    "    samples = np.memmap(\n",
    "        data_f, \n",
    "        dtype=np.float32, \n",
    "        mode='w+', \n",
    "        shape=(len(portion), SAMPLE_SIZE)\n",
    "    )\n",
    "    \n",
    "    ys = np.zeros([len(portion), 2], dtype=np.float32)\n",
    "    \n",
    "    s = 0\n",
    "\n",
    "    for x in tqdm(portion):\n",
    "        \n",
    "        fid = x['fid']\n",
    "        y = [x['y'], 1. - x['y']]\n",
    "        patient = PATIENTS_ENCODING[x['patient']]\n",
    "        \n",
    "        bottlenecks = np.load(BOTTLENECKS_DIR + '/' + fid + '.npy')\n",
    "        samples[s] = np.concatenate((patient, bottlenecks.flatten())).astype(np.float32)\n",
    "        ys[s] = y\n",
    "        \n",
    "        s += 1\n",
    "        \n",
    "    print 'flushing... '\n",
    "    samples.flush()\n",
    "    ys.tofile(ys_f)\n",
    "    print 'Created ', data_f, ys_f; time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6126/6126 [00:01<00:00, 3445.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flushing... \n",
      "Created  out/eval-samples-1.mem\n"
     ]
    }
   ],
   "source": [
    "eval_fids = []\n",
    "i = 0\n",
    "\n",
    "while len(eval_items):\n",
    "\n",
    "    i += 1\n",
    "    data_f = EVAL_FILE%(i)\n",
    "    portion = eval_items[:EVAL_SAMPLES_PER_FILE]\n",
    "    eval_items = eval_items[EVAL_SAMPLES_PER_FILE:]\n",
    "    \n",
    "    samples = np.memmap(\n",
    "        data_f, \n",
    "        dtype=np.float32, \n",
    "        mode='w+', \n",
    "        shape=(len(portion), SAMPLE_SIZE)\n",
    "    )\n",
    "    \n",
    "    s = 0\n",
    "\n",
    "    for x in tqdm(portion):\n",
    "        \n",
    "        fid = x['fid']\n",
    "        patient = PATIENTS_ENCODING[x['patient']]\n",
    "        \n",
    "        bottlenecks = np.load(BOTTLENECKS_DIR + '/' + fid + '.npy')\n",
    "        samples[s] = np.concatenate((patient, bottlenecks.flatten())).astype(np.float32)\n",
    "        eval_fids.append(fid)\n",
    "        \n",
    "        s += 1\n",
    "        \n",
    "    print 'flushing... '\n",
    "    samples.flush()\n",
    "    eval_fids = np.array(eval_fids, dtype=np.str)\n",
    "    np.save(eval_fids)\n",
    "    print 'Created ', data_f; time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.fromfile()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
