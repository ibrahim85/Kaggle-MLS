{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RND = 111\n",
    "np.random.seed(RND)\n",
    "import random\n",
    "random.seed(RND)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "RUN = 'B'\n",
    "MODELS_DIR = '/d3/caches/kaggle-mls-v6/models/' + RUN\n",
    "TFB_DIR = '/tmp-persistent/mls6/' + RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_N_PER_BATCH = 8\n",
    "TRAIN_N_EPOCHS = 111"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VAL_N_PER_BATCH = 8\n",
    "VAL_SIZE = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "WAVES_DIR = 'out/waveforms'\n",
    "\n",
    "SAMPLING_RATE = 400\n",
    "N_SAMPLES = 240000\n",
    "N_CHANNELS = 16\n",
    "\n",
    "N_TIMESTEPS = 9600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure output dirs exist\n",
    "for v in [MODELS_DIR, TFB_DIR]: \n",
    "    if not os.path.isdir(v): \n",
    "        os.makedirs(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load inout files list\n",
    "input_df = pd.read_csv('out/input_files.csv', index_col='file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>path</th>\n",
       "      <th>patient_1</th>\n",
       "      <th>patient_2</th>\n",
       "      <th>patient_3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>file</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2_1288_0.mat</th>\n",
       "      <td>0</td>\n",
       "      <td>/datasets/kaggle/mls/train_2/2_1288_0.mat</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3_725_0.mat</th>\n",
       "      <td>0</td>\n",
       "      <td>/datasets/kaggle/mls/train_3/3_725_0.mat</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_8_0.mat</th>\n",
       "      <td>0</td>\n",
       "      <td>/datasets/kaggle/mls/train_1/1_8_0.mat</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2_1965_0.mat</th>\n",
       "      <td>0</td>\n",
       "      <td>/datasets/kaggle/mls/train_2/2_1965_0.mat</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2_135_0.mat</th>\n",
       "      <td>0</td>\n",
       "      <td>/datasets/kaggle/mls/train_2/2_135_0.mat</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              class                                       path  patient_1  \\\n",
       "file                                                                        \n",
       "2_1288_0.mat      0  /datasets/kaggle/mls/train_2/2_1288_0.mat        0.0   \n",
       "3_725_0.mat       0   /datasets/kaggle/mls/train_3/3_725_0.mat        0.0   \n",
       "1_8_0.mat         0     /datasets/kaggle/mls/train_1/1_8_0.mat        1.0   \n",
       "2_1965_0.mat      0  /datasets/kaggle/mls/train_2/2_1965_0.mat        0.0   \n",
       "2_135_0.mat       0   /datasets/kaggle/mls/train_2/2_135_0.mat        0.0   \n",
       "\n",
       "              patient_2  patient_3  \n",
       "file                                \n",
       "2_1288_0.mat        1.0        0.0  \n",
       "3_725_0.mat         0.0        1.0  \n",
       "1_8_0.mat           0.0        0.0  \n",
       "2_1965_0.mat        1.0        0.0  \n",
       "2_135_0.mat         1.0        0.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split inout files into train/test sets\n",
    "train_df = input_df[input_df['class'] != -1]\n",
    "test_df = input_df[input_df['class'] == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_trainval_files = train_df.index.tolist()\n",
    "X_trainval_patients = np.vstack((train_df['patient_1'], train_df['patient_2'], train_df['patient_3']))\\\n",
    "    .T.astype(np.float32)\n",
    "y_trainval = np.array(train_df['class'], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_batch(X_files=None, X_patients=None, y=None, start_ix=0, n_samples=1, \\\n",
    "              silent=True):\n",
    "    \n",
    "    X_waves_batch = np.zeros((n_samples, N_TIMESTEPS, N_CHANNELS * N_SAMPLES / N_TIMESTEPS), dtype=np.float32)\n",
    "    X_patients_batch = np.zeros((n_samples, X_patients.shape[1]), dtype=np.float32)        \n",
    "    y_batch = np.zeros([n_samples, 2], dtype=np.float32)\n",
    "    \n",
    "    r = range(n_samples) if silent else tqdm(range(n_samples))\n",
    "\n",
    "    for i in r:\n",
    "        ii = (i + start_ix) % len(X_files)\n",
    "        \n",
    "        mat_f = X_files[ii]\n",
    "        \n",
    "        # waves\n",
    "        wave_f = WAVES_DIR + '/' + mat_f + '.mem'\n",
    "        waves = np.fromfile(wave_f, dtype=np.float32).reshape(N_CHANNELS, -1)\n",
    "        \n",
    "        # add noise\n",
    "        waves = waves.flatten()\n",
    "        waves += (np.random.random_sample(N_CHANNELS*N_SAMPLES) - .5) * 0.1\n",
    "        \n",
    "        X_waves_batch[i] = waves.reshape(N_TIMESTEPS, -1)\n",
    "        \n",
    "        # patients\n",
    "        X_patients_batch[i] = X_patients[ii]\n",
    "        \n",
    "        # ys\n",
    "        if type(y[ii]) == np.ndarray:\n",
    "            y_batch[i] = [1., 0.] if y[ii][0] == 1. else [0., 1.]\n",
    "        else:\n",
    "            y_batch[i] = [1., 0.] if y[ii] == 1. else [0., 1.]\n",
    "            \n",
    "    return X_waves_batch, X_patients_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate val data\n",
    "X_train_files, X_val_files, X_train_patients, X_val_patients, y_train, y_val = \\\n",
    "    train_test_split(X_trainval_files, X_trainval_patients, y_trainval, random_state=RND, test_size=VAL_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_N_PER_EPOCH = len(X_train_files) / TRAIN_N_PER_BATCH * TRAIN_N_PER_BATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4360"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_N_PER_EPOCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_ix_train = 0\n",
    "    \n",
    "# training data generator\n",
    "def train_generator():\n",
    "\n",
    "    global start_ix_train\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        b = gen_batch(\n",
    "            X_train_files, X_train_patients, y_train, \n",
    "            start_ix=start_ix_train, n_samples=TRAIN_N_PER_BATCH\n",
    "        )\n",
    "                \n",
    "        start_ix_train += len(b[0])\n",
    "        \n",
    "        yield [b[0], b[1]], b[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_ix_val = 0\n",
    "    \n",
    "# validation data generator\n",
    "def val_generator():\n",
    "\n",
    "    global start_ix_val\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        b = gen_batch(\n",
    "            X_val_files, X_val_patients, y_val, \n",
    "            start_ix=start_ix_val, n_samples=VAL_N_PER_BATCH\n",
    "        )\n",
    "                \n",
    "        start_ix_val += len(b[0])\n",
    "        \n",
    "        yield [b[0], b[1]], b[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = gen_batch(X_val_files, X_val_patients, y_val, start_ix=0, n_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0].shape[1]/9600."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.callbacks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n"
     ]
    }
   ],
   "source": [
    "l = N_CHANNELS * N_SAMPLES\n",
    "n_steps = N_TIMESTEPS # n seconds\n",
    "step_l = l/n_steps\n",
    "print step_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Convolution1D(64, 40, border_mode='same', activation='relu', input_shape=(n_steps, step_l)))\n",
    "model1.add(Convolution1D(64, 40, border_mode='same', activation='relu'))\n",
    "model1.add(MaxPooling1D(pool_length=4))\n",
    "model1.add(Convolution1D(128, 10, border_mode='same', activation='relu'))\n",
    "model1.add(Convolution1D(128, 10, border_mode='same', activation='relu'))\n",
    "model1.add(MaxPooling1D(pool_length=4))\n",
    "model1.add(Convolution1D(128, 10, border_mode='same', activation='relu'))\n",
    "model1.add(Convolution1D(128, 10, border_mode='same', activation='relu'))\n",
    "model1.add(MaxPooling1D(pool_length=4))\n",
    "model1.add(Convolution1D(256, 10, border_mode='same', activation='relu'))\n",
    "model1.add(Convolution1D(256, 10, border_mode='same', activation='relu'))\n",
    "model1.add(MaxPooling1D(pool_length=4))\n",
    "model1.add(Convolution1D(256, 10, border_mode='same', activation='relu'))\n",
    "model1.add(Convolution1D(256, 10, border_mode='same', activation='relu'))\n",
    "model1.add(MaxPooling1D(pool_length=4))\n",
    "model1.add(Flatten())\n",
    "model1.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution1d_1 (Convolution1D)  (None, 9600, 64)      1024064     convolution1d_input_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_2 (Convolution1D)  (None, 9600, 64)      163904      convolution1d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_1 (MaxPooling1D)    (None, 2400, 64)      0           convolution1d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_3 (Convolution1D)  (None, 2400, 128)     82048       maxpooling1d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_4 (Convolution1D)  (None, 2400, 128)     163968      convolution1d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_2 (MaxPooling1D)    (None, 600, 128)      0           convolution1d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_5 (Convolution1D)  (None, 600, 128)      163968      maxpooling1d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_6 (Convolution1D)  (None, 600, 128)      163968      convolution1d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_3 (MaxPooling1D)    (None, 150, 128)      0           convolution1d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_7 (Convolution1D)  (None, 150, 256)      327936      maxpooling1d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_8 (Convolution1D)  (None, 150, 256)      655616      convolution1d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_4 (MaxPooling1D)    (None, 37, 256)       0           convolution1d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_9 (Convolution1D)  (None, 37, 256)       655616      maxpooling1d_4[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_10 (Convolution1D) (None, 37, 256)       655616      convolution1d_9[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_5 (MaxPooling1D)    (None, 9, 256)        0           convolution1d_10[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 2304)          0           maxpooling1d_5[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 2304)          0           flatten_1[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 4056704\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_patient = Input(shape=(3,), name='input_patient')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = merge([model1.output, input_patient], mode='concat')\n",
    "x = Dense(2, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'convolution1d_input_1:0' shape=(?, 9600, 400) dtype=float32>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(input=[model1.input, input_patient], output=[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='SGD', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution1d_input_1 (InputLayer(None, 9600, 400)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_1 (Convolution1D)  (None, 9600, 64)      1024064     convolution1d_input_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_2 (Convolution1D)  (None, 9600, 64)      163904      convolution1d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_1 (MaxPooling1D)    (None, 2400, 64)      0           convolution1d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_3 (Convolution1D)  (None, 2400, 128)     82048       maxpooling1d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_4 (Convolution1D)  (None, 2400, 128)     163968      convolution1d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_2 (MaxPooling1D)    (None, 600, 128)      0           convolution1d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_5 (Convolution1D)  (None, 600, 128)      163968      maxpooling1d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_6 (Convolution1D)  (None, 600, 128)      163968      convolution1d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_3 (MaxPooling1D)    (None, 150, 128)      0           convolution1d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_7 (Convolution1D)  (None, 150, 256)      327936      maxpooling1d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_8 (Convolution1D)  (None, 150, 256)      655616      convolution1d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_4 (MaxPooling1D)    (None, 37, 256)       0           convolution1d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_9 (Convolution1D)  (None, 37, 256)       655616      maxpooling1d_4[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_10 (Convolution1D) (None, 37, 256)       655616      convolution1d_9[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_5 (MaxPooling1D)    (None, 9, 256)        0           convolution1d_10[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 2304)          0           maxpooling1d_5[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 2304)          0           flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_patient (InputLayer)       (None, 3)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_1 (Merge)                  (None, 2307)          0           dropout_1[0][0]                  \n",
      "                                                                   input_patient[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 2)             4616        merge_1[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 4061320\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "# del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils.visualize_util import plot\n",
    "plot(model, to_file='model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import gc\n",
    "\n",
    "scores = []\n",
    "\n",
    "def score_auc():\n",
    "    s = 0\n",
    "    n = len(X_val_msgs)\n",
    "    y_p = model.predict([X_val_msgs[s:s+n],\n",
    "                         X_val_patients[s:s+n]], \n",
    "                        verbose=False)\n",
    "    return metrics.roc_auc_score(y_val[s:s+n].T[0], y_p.T[0])\n",
    "\n",
    "class MyCallback(keras.callbacks.Callback):\n",
    "    def _validate(self):\n",
    "        s = score_auc()\n",
    "        scores.append(s)\n",
    "        print \"\\n\\n AUC = %.5f\\n\"%s; time.sleep(.5)\n",
    "    def on_train_begin(self, epoch, logs={}):\n",
    "        self._validate()\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self._validate()\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/111\n",
      "2712/4360 [=================>............] - ETA: 114s - loss: 0.3165 - acc: 0.9093"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-471bce55eef8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;34m'/e{epoch:02d}-l={loss:.5f}-vl={val_loss:.5f}-a={acc:.5f}-va={val_acc:.5f}.h5'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0msave_weights_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         )\n\u001b[1;32m     16\u001b[0m     ]\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/Keras-1.1.0-py2.7.egg/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe)\u001b[0m\n\u001b[1;32m   1422\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1423\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1424\u001b[0;31m                         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1426\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    generator=train_generator(), \n",
    "    samples_per_epoch=TRAIN_N_PER_EPOCH,\n",
    "    nb_epoch=TRAIN_N_EPOCHS,\n",
    "    validation_data=val_generator(),\n",
    "    nb_val_samples=VAL_SIZE,\n",
    "    callbacks = [\n",
    "#         MyCallback(),\n",
    "        TensorBoard(log_dir=TFB_DIR, histogram_freq=0),\n",
    "        ModelCheckpoint(\n",
    "            MODELS_DIR + \\\n",
    "            '/e{epoch:02d}-l={loss:.5f}-vl={val_loss:.5f}-a={acc:.5f}-va={val_acc:.5f}.h5', \n",
    "            monitor='val_acc', verbose=0, save_best_only=False, \n",
    "            save_weights_only=False, mode='auto'\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:04<00:00, 23.56it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(100)):\n",
    "    np.random.random_sample(N_CHANNELS*N_SAMPLES) / 2. - 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04380665, -0.03585813, -0.0310039 , ..., -0.0230558 ,\n",
       "       -0.04071133,  0.0098319 ])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.random.random_sample(N_CHANNELS*N_SAMPLES) - .5) * 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.array([1.,2.,3.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  2.,  3.])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.42748417,  2.33823995,  3.14727188])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.random_sample(3) + a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
