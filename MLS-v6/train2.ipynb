{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RND = 123\n",
    "np.random.seed(RND)\n",
    "import random\n",
    "random.seed(RND)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "RUN = 'H'\n",
    "MODELS_DIR = '/d3/caches/kaggle-mls-v6/models/' + RUN\n",
    "TFB_DIR = '/tmp-persistent/mls6/' + RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_N_PER_BATCH = 16\n",
    "TRAIN_N_EPOCHS = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VAL_N_PER_BATCH = 8\n",
    "VAL_SIZE = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "WAVES_DIR = 'out/waveforms'\n",
    "\n",
    "SAMPLING_RATE = 400\n",
    "N_SAMPLES = 240000\n",
    "N_CHANNELS = 16\n",
    "\n",
    "N_TIMESTEPS = 9600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure output dirs exist\n",
    "for v in [MODELS_DIR, TFB_DIR]: \n",
    "    if not os.path.isdir(v): \n",
    "        os.makedirs(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load inout files list\n",
    "input_df = pd.read_csv('out/input_files.csv', index_col='file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>path</th>\n",
       "      <th>patient_1</th>\n",
       "      <th>patient_2</th>\n",
       "      <th>patient_3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>file</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2_1288_0.mat</th>\n",
       "      <td>0</td>\n",
       "      <td>/datasets/kaggle/mls/train_2/2_1288_0.mat</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3_725_0.mat</th>\n",
       "      <td>0</td>\n",
       "      <td>/datasets/kaggle/mls/train_3/3_725_0.mat</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_8_0.mat</th>\n",
       "      <td>0</td>\n",
       "      <td>/datasets/kaggle/mls/train_1/1_8_0.mat</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2_1965_0.mat</th>\n",
       "      <td>0</td>\n",
       "      <td>/datasets/kaggle/mls/train_2/2_1965_0.mat</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2_135_0.mat</th>\n",
       "      <td>0</td>\n",
       "      <td>/datasets/kaggle/mls/train_2/2_135_0.mat</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              class                                       path  patient_1  \\\n",
       "file                                                                        \n",
       "2_1288_0.mat      0  /datasets/kaggle/mls/train_2/2_1288_0.mat        0.0   \n",
       "3_725_0.mat       0   /datasets/kaggle/mls/train_3/3_725_0.mat        0.0   \n",
       "1_8_0.mat         0     /datasets/kaggle/mls/train_1/1_8_0.mat        1.0   \n",
       "2_1965_0.mat      0  /datasets/kaggle/mls/train_2/2_1965_0.mat        0.0   \n",
       "2_135_0.mat       0   /datasets/kaggle/mls/train_2/2_135_0.mat        0.0   \n",
       "\n",
       "              patient_2  patient_3  \n",
       "file                                \n",
       "2_1288_0.mat        1.0        0.0  \n",
       "3_725_0.mat         0.0        1.0  \n",
       "1_8_0.mat           0.0        0.0  \n",
       "2_1965_0.mat        1.0        0.0  \n",
       "2_135_0.mat         1.0        0.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in input_df.iterrows():\n",
    "    f = r[0]\n",
    "    cls = r[1]['class']\n",
    "    m = re.findall(u'\\d+_\\d+_(\\d+)', f)\n",
    "    if len(m) > 0:\n",
    "        c = int(m[0])\n",
    "        if c != cls: print c, cls, f, m; break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split inout files into train/test sets\n",
    "train_df = input_df[input_df['class'] != -1]\n",
    "test_df = input_df[input_df['class'] == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_trainval_files = train_df.index.tolist()\n",
    "X_trainval_patients = np.vstack((train_df['patient_1'], train_df['patient_2'], train_df['patient_3']))\\\n",
    "    .T.astype(np.float32)\n",
    "y_trainval = np.array(train_df['class'], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_batch(X_files=None, X_patients=None, y=None, start_ix=0, n_samples=1, \\\n",
    "              silent=True, indexes=None, dropout_f=0.05):\n",
    "\n",
    "    if not indexes is None: n_samples = len(indexes)\n",
    "\n",
    "    X_waves_batch = np.zeros((n_samples, N_TIMESTEPS, N_CHANNELS * N_SAMPLES / N_TIMESTEPS), dtype=np.float32)\n",
    "    X_patients_batch = np.zeros((n_samples, X_patients.shape[1]), dtype=np.float32)        \n",
    "    y_batch = np.zeros([n_samples, 2], dtype=np.float32)\n",
    "    \n",
    "    r = range(n_samples) if silent else tqdm(range(n_samples))\n",
    "\n",
    "    for i in r:\n",
    "        \n",
    "        if not indexes is None:\n",
    "            ii = indexes[i]\n",
    "        else:\n",
    "            ii = (i + start_ix) % len(X_files)\n",
    "        \n",
    "        mat_f = X_files[ii]\n",
    "        \n",
    "        # waves\n",
    "        wave_f = WAVES_DIR + '/' + mat_f + '.mem'\n",
    "        waves = np.fromfile(wave_f, dtype=np.float32).reshape(N_CHANNELS, -1)\n",
    "        \n",
    "        # add noise\n",
    "        if dropout_f > 0:\n",
    "            waves = waves.flatten()\n",
    "            waves[np.random.randint(0, len(waves) - 1, int(len(waves) * dropout_f))] = 0.\n",
    "        \n",
    "        X_waves_batch[i] = waves.reshape(N_TIMESTEPS, -1)\n",
    "        \n",
    "        # patients\n",
    "        X_patients_batch[i] = X_patients[ii]\n",
    "        \n",
    "        # ys\n",
    "        if type(y[ii]) == np.ndarray:\n",
    "            y_batch[i] = [1., 0.] if y[ii][0] == 1. else [0., 1.]\n",
    "        else:\n",
    "            y_batch[i] = [1., 0.] if y[ii] == 1. else [0., 1.]\n",
    "            \n",
    "    return X_waves_batch, X_patients_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate val data\n",
    "X_train_files, X_val_files, X_train_patients, X_val_patients, y_train, y_val = \\\n",
    "    train_test_split(X_trainval_files, X_trainval_patients, y_trainval, random_state=RND, test_size=VAL_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4240\n"
     ]
    }
   ],
   "source": [
    "TRAIN_N_PER_EPOCH = len(X_train_files) / TRAIN_N_PER_BATCH * TRAIN_N_PER_BATCH\n",
    "print TRAIN_N_PER_EPOCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_ix_val = 0\n",
    "\n",
    "# training data generator\n",
    "def train_generator(X_files=X_train_files, X_patients=X_train_patients, y=y_train, n=TRAIN_N_PER_BATCH):\n",
    "    \n",
    "#     indexes = np.random.randint(0, len(X_files) - 1, TRAIN_N_PER_BATCH, dtype=np.int)\n",
    "\n",
    "    global start_ix_val\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        b = gen_batch(\n",
    "            X_files, X_patients, y, \n",
    "            n_samples=n, start_ix=start_ix_val, dropout_f=0\n",
    "        )\n",
    "        \n",
    "        start_ix_val += n\n",
    "        \n",
    "        yield [b[0], b[1]], b[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_ix_val = 0\n",
    "    \n",
    "# validation data generator\n",
    "def val_generator():\n",
    "\n",
    "    global start_ix_val\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        b = gen_batch(\n",
    "            X_val_files, X_val_patients, y_val, \n",
    "            start_ix=start_ix_val, n_samples=VAL_N_PER_BATCH, dropout_f=0\n",
    "        )\n",
    "                \n",
    "        start_ix_val += len(b[0])\n",
    "        \n",
    "        yield [b[0], b[1]], b[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# b = gen_batch(X_val_files, X_val_patients, y_val, start_ix=0, n_samples=1, dropout_f=0.01)\n",
    "# b[0].shape[1]/9600.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.mean(b[0][0].flatten() == 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(b[0][0].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.callbacks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n"
     ]
    }
   ],
   "source": [
    "l = N_CHANNELS * N_SAMPLES\n",
    "n_steps = N_TIMESTEPS # n seconds\n",
    "step_l = l/n_steps\n",
    "print step_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Convolution1D(64, 10, border_mode='same', activation='relu', input_shape=(n_steps, step_l)))\n",
    "model1.add(Convolution1D(64, 10, border_mode='same', activation='relu'))\n",
    "model1.add(MaxPooling1D(pool_length=4))\n",
    "model1.add(Convolution1D(128, 10, border_mode='same', activation='relu'))\n",
    "model1.add(Convolution1D(128, 10, border_mode='same', activation='relu'))\n",
    "model1.add(MaxPooling1D(pool_length=4))\n",
    "model1.add(Convolution1D(128, 10, border_mode='same', activation='relu'))\n",
    "model1.add(Convolution1D(128, 10, border_mode='same', activation='relu'))\n",
    "model1.add(MaxPooling1D(pool_length=4))\n",
    "model1.add(Convolution1D(256, 10, border_mode='same', activation='relu'))\n",
    "model1.add(Convolution1D(256, 10, border_mode='same', activation='relu'))\n",
    "model1.add(MaxPooling1D(pool_length=4))\n",
    "model1.add(Convolution1D(256, 10, border_mode='same', activation='relu'))\n",
    "model1.add(Convolution1D(256, 10, border_mode='same', activation='relu'))\n",
    "model1.add(MaxPooling1D(pool_length=4))\n",
    "model1.add(Convolution1D(512, 1, border_mode='same', activation='relu'))\n",
    "model1.add(Convolution1D(512, 1, border_mode='same', activation='relu'))\n",
    "model1.add(MaxPooling1D(pool_length=4))\n",
    "model1.add(Convolution1D(1024, 2, border_mode='same', activation='relu'))\n",
    "model1.add(Convolution1D(1024, 1, border_mode='same', activation='relu'))\n",
    "model1.add(MaxPooling1D(pool_length=2))\n",
    "model1.add(Flatten())\n",
    "# model1.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution1d_1 (Convolution1D)  (None, 9600, 64)      256064      convolution1d_input_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_2 (Convolution1D)  (None, 9600, 64)      41024       convolution1d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_1 (MaxPooling1D)    (None, 2400, 64)      0           convolution1d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_3 (Convolution1D)  (None, 2400, 128)     82048       maxpooling1d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_4 (Convolution1D)  (None, 2400, 128)     163968      convolution1d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_2 (MaxPooling1D)    (None, 600, 128)      0           convolution1d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_5 (Convolution1D)  (None, 600, 128)      163968      maxpooling1d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_6 (Convolution1D)  (None, 600, 128)      163968      convolution1d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_3 (MaxPooling1D)    (None, 150, 128)      0           convolution1d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_7 (Convolution1D)  (None, 150, 256)      327936      maxpooling1d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_8 (Convolution1D)  (None, 150, 256)      655616      convolution1d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_4 (MaxPooling1D)    (None, 37, 256)       0           convolution1d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_9 (Convolution1D)  (None, 37, 256)       655616      maxpooling1d_4[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_10 (Convolution1D) (None, 37, 256)       655616      convolution1d_9[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_5 (MaxPooling1D)    (None, 9, 256)        0           convolution1d_10[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_11 (Convolution1D) (None, 9, 512)        131584      maxpooling1d_5[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_12 (Convolution1D) (None, 9, 512)        262656      convolution1d_11[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_6 (MaxPooling1D)    (None, 2, 512)        0           convolution1d_12[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_13 (Convolution1D) (None, 2, 1024)       1049600     maxpooling1d_6[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_14 (Convolution1D) (None, 2, 1024)       1049600     convolution1d_13[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_7 (MaxPooling1D)    (None, 1, 1024)       0           convolution1d_14[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 1024)          0           maxpooling1d_7[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 1024)          0           flatten_1[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 5659264\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_patient = Input(shape=(3,), name='input_patient')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = merge([model1.output, input_patient], mode='concat')\n",
    "# x = Dense(128, activation='relu')(x)\n",
    "# x = Dropout(0.5)(x)\n",
    "x = Dense(2, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'convolution1d_input_1:0' shape=(?, 9600, 400) dtype=float32>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(input=[model1.input, input_patient], output=[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='SGD', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution1d_input_1 (InputLayer(None, 9600, 400)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_1 (Convolution1D)  (None, 9600, 64)      256064      convolution1d_input_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_2 (Convolution1D)  (None, 9600, 64)      41024       convolution1d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_1 (MaxPooling1D)    (None, 2400, 64)      0           convolution1d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_3 (Convolution1D)  (None, 2400, 128)     82048       maxpooling1d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_4 (Convolution1D)  (None, 2400, 128)     163968      convolution1d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_2 (MaxPooling1D)    (None, 600, 128)      0           convolution1d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_5 (Convolution1D)  (None, 600, 128)      163968      maxpooling1d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_6 (Convolution1D)  (None, 600, 128)      163968      convolution1d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_3 (MaxPooling1D)    (None, 150, 128)      0           convolution1d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_7 (Convolution1D)  (None, 150, 256)      327936      maxpooling1d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_8 (Convolution1D)  (None, 150, 256)      655616      convolution1d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_4 (MaxPooling1D)    (None, 37, 256)       0           convolution1d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_9 (Convolution1D)  (None, 37, 256)       655616      maxpooling1d_4[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_10 (Convolution1D) (None, 37, 256)       655616      convolution1d_9[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_5 (MaxPooling1D)    (None, 9, 256)        0           convolution1d_10[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_11 (Convolution1D) (None, 9, 512)        131584      maxpooling1d_5[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_12 (Convolution1D) (None, 9, 512)        262656      convolution1d_11[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_6 (MaxPooling1D)    (None, 2, 512)        0           convolution1d_12[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_13 (Convolution1D) (None, 2, 1024)       1049600     maxpooling1d_6[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_14 (Convolution1D) (None, 2, 1024)       1049600     convolution1d_13[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_7 (MaxPooling1D)    (None, 1, 1024)       0           convolution1d_14[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 1024)          0           maxpooling1d_7[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 1024)          0           flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_patient (InputLayer)       (None, 3)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_1 (Merge)                  (None, 1027)          0           dropout_1[0][0]                  \n",
      "                                                                   input_patient[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 2)             2056        merge_1[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 5661320\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "# del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils.visualize_util import plot\n",
    "plot(model, to_file='model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import gc\n",
    "\n",
    "scores = []\n",
    "\n",
    "def score_auc():\n",
    "    y_p = model.predict_generator(val_generator(), VAL_SIZE)\n",
    "    return metrics.roc_auc_score(y_val, y_p.T[0])\n",
    "\n",
    "class MyCallback(keras.callbacks.Callback):\n",
    "    def _validate(self):\n",
    "        s = score_auc()\n",
    "        scores.append(s)\n",
    "        print \"\\n\\n AUC = %.5f\\n\"%s; time.sleep(.5)\n",
    "    def on_train_begin(self, epoch, logs={}):\n",
    "        self._validate()\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self._validate()\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "def cb_shuffle_train_data(batch, logs):\n",
    "    global X_train_files, X_train_patients, y_train\n",
    "    X_train_files, X_train_patients, y_train = \\\n",
    "        shuffle(X_train_files, X_train_patients, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " AUC = 0.50087\n",
      "\n",
      "Epoch 1/123\n",
      "1360/4240 [========>.....................] - ETA: 83s - loss: 0.4550 - acc: 0.9081"
     ]
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    generator=train_generator(), \n",
    "    samples_per_epoch=TRAIN_N_PER_EPOCH,\n",
    "    nb_epoch=TRAIN_N_EPOCHS,\n",
    "    validation_data=val_generator(),\n",
    "    nb_val_samples=VAL_SIZE,\n",
    "    nb_worker=1,\n",
    "    pickle_safe=False,\n",
    "    max_q_size=20,\n",
    "    callbacks = [\n",
    "        MyCallback(),\n",
    "        TensorBoard(log_dir=TFB_DIR, histogram_freq=0),\n",
    "        ModelCheckpoint(\n",
    "            MODELS_DIR + \\\n",
    "            '/e{epoch:02d}-l={loss:.5f}-vl={val_loss:.5f}-a={acc:.5f}-va={val_acc:.5f}.h5', \n",
    "            monitor='val_acc', verbose=0, save_best_only=False, \n",
    "            save_weights_only=False, mode='auto'\n",
    "        ),\n",
    "#         LambdaCallback(on_epoch_begin=cb_shuffle_train_data)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
